# Youtube-Comment-Analysis
Basic sentiment analysis of comments on a youtube video using a builtin python package "Vader Lexicon" and "Youtube Data API".

# How it is made
I have simply used "Youtube Data API" which is available on "Google Developers Console" to scrap youtube comments of a particular video.Then I have made use of python library called "NLTK" (Natural Language Toolkit), a platform for building python programs to work with Human language data. More specifically, what I have used is called VADER (Valence Aware Dictionary and Sentiment Reasoner) which is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed on social media. I have combined this vader lexicon and youtube data api to give a machine generated report on sentiments of comments that are posted (Expressed) on a particular video.

**Scoring Procedure for Sentiment Analysis**
`VADER Lexicon:`
The VADER sentiment analysis tool has a dictionary of words with pre-assigned sentiment values. Words like "Good" or "Amazing" have positive values, while words like "Bad" or "Sad" have negative values.
`Compound Score Calculation:`
Each comment is analyzed, and a compound score is calculated. The compound score is a single metric that gives an overall sentiment value ranging from -1 (most negative) to +1 (most positive).
`Sentiment Labeling:`
Comments are labeled based on their compound score:
Positive sentiment: compound score >= 0.05
Neutral sentiment: -0.05 < compound score < 0.05
Negative sentiment: compound score <= -0.05

# Applications
It can be used by youtube content creators and channel owners to analyse the response of audience viewing and commenting on their videos. Since there are millions of comments made on youtube each day it can become difficult to read all the comments on a video, but since it is also important to know the feedback and what people think of a video or a particular content this can be used as youtube report to know if the comments on a video are **Positive, Negative or Neutral**. This is made interactive and easy to understand by concluding the report with **final result** of all the calculations and a **piechart** containing info about percentage of `positive`, `negative` and `neutral` comments.

# To run this
You will have to install some libraries. `Run:`
1. `pip install vaderSentiment`
2. `pip install httplib2`
3. `pip install google-api-python-client`
4. `pip install csv`
5. `pip install oauth2client`

**You will also have to set up Google Cloud:**
1. Go to "Google Developers Console".
2. Enable "Youtube Data API".
3. Create Credentials.
4. Download the credentials to `client_secrets.json`.

**Running the program**

Just type in your terminal `python3 youcomment{main file}.py --videoid=fc93EBfcb7w{example videoid}` and press enter.


**YouTube Comment Analyzer**
This project is designed to authenticate with the YouTube API, scrape comments from a specified YouTube video, perform sentiment analysis on these comments using the `VADER sentiment analysis` tool, and then generate a report on the results.

`VADER`( Valence Aware Dictionary for Sentiment Reasoning) is an `NLTK module` that provides sentiment scores based on the words used. It is a rule-based sentiment analyzer in which the terms are generally labeled as per their semantic orientation as either positive or negative.


**Main Script**

The main script performs the following tasks:

**Importing Libraries:**
The script imports several libraries required for its operations, including time, httplib2, os, sys, csv, apiclient, oauth2client, vaderSentiment, matplotlib.pyplot, and argparse.

**Global Variables:**
timer, count, fresult: Variables for timing, counting comments, and storing results.
commentbot: Instance of the VADER sentiment analyzer.
Various constants for YouTube API configuration and authentication.

**Authentication Function:**
get_authenticated_service(args): Authenticates and returns a YouTube API service instance using OAuth2.

**Comment Retrieval Function:**
get_comment_threads(youtube, video_id, comments=[], token=""): Recursively retrieves comments from a YouTube video, handling `pagination`(Pagination is a technique used to divide a large dataset into smaller, more manageable pieces, often called "pages". This is especially useful when dealing with APIs that return large amounts of data. Instead of returning all the data in a single response, the API returns a subset of the data along with information on how to retrieve the next subset.) with nextPageToken.

**Main Execution:**
Parses the --videoid argument to get the YouTube video ID.
Calls get_authenticated_service to authenticate and get the YouTube API service instance.
Calls get_comment_threads to scrape comments and save them to a CSV file.
Analyzes the sentiment of each comment using VADER and updates fresult.
Generates a detailed report of the sentiment analysis, including counts and percentages of positive, negative, and neutral comments. It also generates a pie chart using Matplotlib to visually represent the sentiment distribution.
Error Handling
HttpError Handling: Catches and prints HTTP errors during the API calls.


**client_secrets.json**
The client_secrets.json file is required for OAuth 2.0 authentication, which is necessary to access the YouTube Data API securely and perform actions like retrieving comments from a video. This file contains the client ID, client secret, and other credentials needed to authenticate your application with Google's OAuth 2.0 servers.


**youcomment.py-oauth2.json**
The youcomment.py-oauth2.json file stores OAuth 2.0 credentials for your application to securely access the YouTube Data API on behalf of the user. This file is automatically created and updated by the oauth2client library when the user authorizes your application. 


**youtubecommentscraper.py-oauth2.json**
The youtubecommentscraper.py-oauth2.json file, like the youcomment.py-oauth2.json file mentioned earlier, is used to store OAuth 2.0 credentials for your application. These credentials are essential for securely accessing the YouTube Data API on behalf of the user.